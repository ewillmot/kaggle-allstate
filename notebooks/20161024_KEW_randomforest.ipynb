{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Ok, we know that taking some continuous variables out of the mix improves the score. Now, I want to try using one-hot encoding on the categorical variables, removing highly correlated variables, and tweaking the RF parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc = '/Users/elena/Documents/Kaggle/Allstate/data/'\n",
    "train = pd.read_csv(os.path.join(loc,'train.csv'))\n",
    "train.drop('id',axis=1,inplace=True)\n",
    "\n",
    "test = pd.read_csv(os.path.join(loc,'test.csv'))\n",
    "ids = test['id']\n",
    "test.drop('id',axis=1,inplace=True)\n",
    "\n",
    "submission = pd.read_csv(os.path.join(loc,\"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical:  116\n",
      "Continuous:  14\n"
     ]
    }
   ],
   "source": [
    "# List of categorical columns\n",
    "keepcats = [col for col in train.columns if 'cat' in col]\n",
    "# List of continuous columns\n",
    "keepcont = [col for col in train.columns if 'cont' in col]\n",
    "\n",
    "print 'Categorical: ',len(keepcats)\n",
    "print 'Continuous: ',len(keepcont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elena/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/elena/anaconda/lib/python2.7/site-packages/pandas/core/frame.py:2754: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>log-loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.245921</td>\n",
       "      <td>0.187583</td>\n",
       "      <td>0.789639</td>\n",
       "      <td>0.310061</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>7.702186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.614134</td>\n",
       "      <td>0.885834</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>7.157424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.358319</td>\n",
       "      <td>0.484196</td>\n",
       "      <td>0.236924</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>8.008063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.555782</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.373816</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>6.845720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.159990</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.473202</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>7.924380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cont2     cont3     cont4     cont5     cont7    cont8    cont9  \\\n",
       "0  0.245921  0.187583  0.789639  0.310061  0.335060  0.30260  0.67135   \n",
       "1  0.737068  0.592681  0.614134  0.885834  0.436585  0.60087  0.35127   \n",
       "2  0.358319  0.484196  0.236924  0.397069  0.315545  0.27320  0.26076   \n",
       "3  0.555782  0.527991  0.373816  0.422268  0.391128  0.31796  0.32128   \n",
       "4  0.159990  0.527991  0.473202  0.704268  0.247408  0.24564  0.22089   \n",
       "\n",
       "    cont10    cont12    cont13    cont14  log-loss  \n",
       "0  0.83510  0.594646  0.822493  0.714843  7.702186  \n",
       "1  0.43919  0.366307  0.611431  0.304496  7.157424  \n",
       "2  0.32446  0.373424  0.195709  0.774425  8.008063  \n",
       "3  0.44467  0.321570  0.605077  0.602642  6.845720  \n",
       "4  0.21230  0.202213  0.246011  0.432606  7.924380  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newlist = deepcopy(keepcont)\n",
    "newlist.remove(\"cont1\")\n",
    "newlist.remove(\"cont11\")\n",
    "newlist.remove(\"cont6\")\n",
    "newlist.append(\"loss\")\n",
    "\n",
    "dataset = train[newlist]\n",
    "dataset['loss']=np.log(dataset['loss'])\n",
    "dataset.rename(columns={'loss':'log-loss'},inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "One-hot encoding, and thinning of feature list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176\n",
      "(188318, 1176)\n"
     ]
    }
   ],
   "source": [
    "## Now let's code up the categorical data (0's and 1's instead of ABC's)\n",
    "labels = []\n",
    "cols = train.columns\n",
    "newlabels = []\n",
    "for i in range(0,116):\n",
    "    trainer = train[cols[i]].unique()\n",
    "    tester = test[cols[i]].unique()\n",
    "    # We want the intersection of labels from the training and testing datasets\n",
    "    # in case there are labels in the test dataset that don't show up in the training dataset.\n",
    "    labels.append(list(set(trainer) | set(tester)))    \n",
    "    \n",
    "    for thing in labels[-1]:\n",
    "        newlabels.append(cols[i]+'-'+str(thing))\n",
    "\n",
    "#One hot encode all categorical attributes\n",
    "cats = []\n",
    "for i in range(0, 116):\n",
    "    #Label encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(labels[i])\n",
    "    feature = label_encoder.transform(train.iloc[:,i])\n",
    "    feature = feature.reshape(train.shape[0], 1)\n",
    "    \n",
    "    \n",
    "    #One hot encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False,n_values=len(labels[i]))\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    cats.append(feature)\n",
    "\n",
    "# Make a 2D array from a list of 1D arrays\n",
    "encoded_cats = np.column_stack(cats)\n",
    "print len(newlabels)\n",
    "print encoded_cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176 1166\n"
     ]
    }
   ],
   "source": [
    "# Based on analysis done in Kaggle forum, get rid of a couple highly\n",
    "# correlated categorical variables:\n",
    "get_rid_of = list(['cat2-','cat6-','cat8-','cat7-','cat16-'])\n",
    "new_cat_list = []\n",
    "\n",
    "for lab in newlabels:\n",
    "    ans = 'yes'\n",
    "    for bad in get_rid_of:\n",
    "        if bad in lab:\n",
    "            ans = 'no'\n",
    "            \n",
    "    if ans=='yes':\n",
    "        new_cat_list.append(lab)\n",
    "\n",
    "print len(newlabels),len(new_cat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inds = [i for i in range(len(newlabels)) if newlabels[i] in new_cat_list]\n",
    "df = pd.DataFrame(encoded_cats[:,inds],columns=new_cat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All categorical:  1217.57527133\n",
      "Some categorical:  1225.38317237\n"
     ]
    }
   ],
   "source": [
    "# Merge continuous and categorical\n",
    "final_data = pd.concat([dataset,df],axis=1)\n",
    "\n",
    "y = final_data['log-loss']\n",
    "x = final_data.drop('log-loss',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=.5)\n",
    "model_some = RandomForestRegressor(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "\n",
    "model_some.fit(X_train,y_train)\n",
    "x_pred = model_some.predict(X_test)\n",
    "\n",
    "mae_some = mean_absolute_error(np.exp(y_test),np.exp(x_pred))\n",
    "\n",
    "\n",
    "\n",
    "#_--------------------------\n",
    "catdf = pd.DataFrame(encoded_cats,columns=newlabels)\n",
    "final_full = pd.concat([dataset,catdf],axis=1)\n",
    "y2 = final_full['log-loss']\n",
    "x2 = final_full.drop('log-loss',axis=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=.5)\n",
    "model_all = RandomForestRegressor(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "\n",
    "model_all.fit(X_train2,y_train2)\n",
    "x_pred2 = model_all.predict(X_test2)\n",
    "\n",
    "mae_all = mean_absolute_error(np.exp(y_test2),np.exp(x_pred2))\n",
    "\n",
    "print 'All categorical: ',mae_all\n",
    "print 'Some categorical: ',mae_some"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with RF parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "nestimators = np.arange(10,100,10)\n",
    "maes = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=.1)\n",
    "for nest in nestimators:\n",
    "    print nest\n",
    "    model = RandomForestRegressor(n_estimators=nest)\n",
    "    model.fit(X_train,y_train)\n",
    "    maes.append(mean_absolute_error(np.exp(y_test),np.exp(model.predict(x_test))))\n",
    "    \n",
    "sns.set_context('poster')\n",
    "plt.plot(nestimators,maes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
